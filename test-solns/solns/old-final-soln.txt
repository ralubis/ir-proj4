                        Solutions to CS371R IR Final 
                               Fall 2018
                        ----------------------------

Ans 1)

The words "of", "at", "and" and "the" are ignored because they are in
the list of stop words.

             tf      idf                      tf*idf
Austin       1/2     log(20000/100) = 7.64    3.82
Texas        1       log(20000/500) = 5.32    5.32
state        1/2     log(20000/15000) = 0.42  0.21
University   1/2     log(20000/10000) = 1     0.5



Ans 2)

Assuming Zipf's law, the fraction of words that appear exactly n times
is: 1/n(n+1)

Therefore:

  The fraction of words that appear exactly once    = 1/1(1+1) = 1/2
                                            twice   = 1/2(2+1) = 1/6
                                            3 times = 1/3(3+1) = 1/12

                                  more than 3 times = 1 - (1/2+1/6+1/12)
                                                    = 1/4



Ans 3)

            austin bats club fan free ice mexican night tailed wings
original    1      1    0    0   0    0   0       0     0      0
relevant    1      1    0    0   0    0   0       1     0      1
            0      1    0    0   1    0   1       0     1      0
irrelevant  1      1    1    1   0    1   0       0     0      0
new query:  1      2   -1   -1   1   -1   1       1     1      1

(new query = alpha*original + beta*relevant - gamma*irrelevant)



Ans 4)

Number of correct extractions in the solution template (N) = 7
Number of slot/value pairs extracted by the IE system (E)  = 4

Number of extracted slot/value pairs that are correct (C)  = 2
(i.e. "Platform: DOS" and "Area: Voice Mail")

Precision (P) = C/E = 2/4 = 0.5
Recall (R)    = C/N = 2/7 = 0.286

F-measure = harmonic mean of P and R
          = (2 x P x R)/(P + R)
          = 0.364

Ans 5)

A B C D E

Iteration 1:
A = [0.0, 0.0, 0.0, 2.0, 3.0]
H = [3.0, 5.0, 5.0, 0.0, 0.0]
Norm A = [0.0, 0.0, 0.0, 0.5547, 0.8321]
Norm H = [0.3906, 0.6509, 0.6509, 0.0, 0.0]

Iteration 2:
A = [0.0, 0.0, 0.0, 1.3019, 1.6925]
H = [1.6925, 2.9943, 2.9943, 0.0, 0.0]
Norm A = [0.0, 0.0, 0.0, 0.6097, 0.7926]
Norm H = [0.3711, 0.6566, 0.6566, 0.0, 0.0]

Iteration 3:
A = [0.0, 0.0, 0.0, 1.3132, 1.6843]
H = [1.6843, 2.9976, 2.9976, 0.0, 0.0]
Norm A = [0.0, 0.0, 0.0, 0.6149, 0.7886]
Norm H = [0.3692, 0.6571, 0.6571, 0.0, 0.0]



Ans 6)

A B C D

R = [0.25, 0.25, 0.25, 0.25]
E = [0.0375, 0.0375, 0.0375, 0.0375]

Iteration 1:
R' = [0.0375, 0.0375, 0.4625, 0.25]
Norm R = [0.0476, 0.0476, 0.5873, 0.3175]

Iteration 2:
R' = [0.0375, 0.0375, 0.1184, 0.5367]
Norm R = [0.0514, 0.0514, 0.1622, 0.7351]

Iteration 3:
R' = [0.0375, 0.0375, 0.1248, 0.1754]
Norm R = [0.0999, 0.0999, 0.3326, 0.4675]


Ans 7)

a) The prototype model may fail to be consistent when one of the
   categories are polymorphic (or disjunctive).  But this is not a
   necessary condition.

   To obtain full score, the graph must have the following properties:

   1. Each prototype vector must roughly bisect the document vectors
      of the same category.

   2. The student must clearly show which training document is 
      misclassified (i.e. the document vector should make a smaller
      angle with the prototype vector of the WRONG category).

b) No.  A training document would be misclassified if the two most
   similar training documents (not including itself) are in a
   different category.


 
Ans 8)

a) 

P(Systems) = 0.5 x 0.05 x 0.3 x 0.05 x (1-0.3) x 0.35 / P(E)
           = 9.19E-5 /P(E)
P(Theory)  = 0.01 x 0.01 x 0.4 x 0.8 x (1-0.02) x 0.4 / P(E)
           = 1.25E-5 /P(E)
P(AI)      = 0.2 x 0.5 x 0.6 x 0.1 x x (1-0.01) x 0.25 / P(E)
           = 1.48E-3 /P(E)

P(E) = 9.19E-5 + 1.25E-5 + 1.48E-3 = 1.59E-3

P(Systems) = 0.058
P(Theory)  = 0.0079
P(AI)      = 0.93

b)

P(Systems) = (1-0.05) x 0.3 x (1-0.05) x 0.5 x 0.3 x 0.35 / P(E) 
           = 1.42E-2 /P(E)
P(Theory)  = (1-0.8) x 0.4 x (1-0.01) x 0.01 x 0.02 x 0.4 / P(E) 
           = 6.34E-6 /P(E)
P(AI)      = (1-0.10) x 0.6 x (1-0.5) x 0.2 x 0.01 x 0.25 / P(E) 
           = 1.35E-4 /P(E)

P(E) = 1.42E-2 + 6.34E-6 + 1.35E-4 = 1.43-2

P(Systems) = 0.99
P(Theory)  = 0.00044
P(AI)      = 0.0094

Ans 9)

# positives = 7 + 4 + 0 = 11
P(red | positive) = (7 + 1*1/3) / (11 + 1) = 0.611
P(blue | positive) = (4 + 1*1/3) / (11 + 1) = 0.361
P(blue | positive) = (0 + 1*1/3) / (11 + 1) = 0.028

# negatives = 0 + 3 + 9 = 12
P(red | negative) = (0 + 1*1/3) / (12 + 1) = 0.026
P(blue | negative) = (3 + 1*1/3) / (12 + 1) = 0.256
P(green | negative) = (9 + 1*1/3) / (12 + 1) = 0.718


Ans 10)

        alpha  beta  gamma
Doc1    2      0     1
Doc2    1      1     0
Doc3    1      0     1
Doc4    2      0     0

length(Doc1) = (4+1)^.5 = 2.236
length(Doc2) = (1+1)^.5 = 1.414
length(Doc3) = (1+1)^.5 = 1.414
length(Doc4) = 4^.5 = 2

cos(Doc1, Doc2) = 2/(2.236 x 1.414) = 0.633
cos(Doc1, Doc3) = (2+1)/(2.236 x 1.414) = 0.949
cos(Doc1, Doc4) = 4/(2.236 x 2) = 0.894
cos(Doc2, Doc3) = 1/(1.414 x 1.414) = 0.5
cos(Doc2, Doc4) = 2/(1.414 x 2) = 0.707
cos(Doc3, Doc4) = 2/(1.414 x 2) = 0.707

Iteration 1:

C1 = Doc1
C2 = Doc2
C3 = Doc3
C4 = Doc4
Most similar clusters:  C1 and C3 (because sim(Doc1, Doc3) = 0.949)
New Cluster C13
sim(C13,C2) = max(0.633,0.5) = 0.633
sim(C13,C4) = max(0.894,0.707) = 0.894

Iteration 2:

C13 = Doc1, Doc3
C2 = Doc2
C4 = Doc4
Most similar clusters:  C13 and C4 (because sim(C13, C4) = 0.894)
New Cluster C134
sim(C134,C2) = max(0.633,0.707) = 0.707

Iteration 3:

C134 = Doc1, Doc3, Doc4
C2 = Doc2
Most similar clusters:  C134 and C2

Final cluster hierarchy:

                     (Doc1, Doc2, Doc3, Doc4)
                                 |
            (Doc1, Doc3, Doc4)-------(Doc2)
                     |
      (Doc1, Doc3)-------(Doc4)
            |
   (Doc1)-------(Doc3)



Ans 11)

w(a,1) = 0.04 * (-1) = -0.04
w(a,2) = 0.04 * 1 = 0.04
w(a,3) = 0.06 * 0.933 = 0.056
w(a,4) = 0.06 * 0.982 = 0.059

Two nearest neightbors are user 3 and 4

r_av(3) = 25/5 = 5
r_av(4) = 20/5 = 4

p(a,D) = (9 + 5 + 1)/3 + (0.056 * (9-5) + 0.059*(8-4))/(0.056 + 0.059)
       = 9
p(a,E) = (9 + 5 + 1)/3 + (0.056 * (3-5) + 0.059*(1-4))/(0.056 + 0.059) 
       = 2.5


Ans 12) 1 point for each question, including extra credit

a) Dot product similarity does not take the length of vectors into
account, while cosine similarity normalizes the similarity value by
the vector lengths.  As a result, cosine similarity provides better
similarity estimates when vectors have varying lengths.

b) Boolean retrieval does only exact query matching and has very rigid
set of operators (e.g. AND, OR), using which it is difficult to
control the number of retrievals or rank them. VSR can give partial
document matches and rank results, also taking into account local and
global word frequencies. So, typically VSR gives better results than
Boolean.

c) Inverted index is a data structure that links attribute values to
lists of objects that the values occur in.  It is a critical part of
an IR system because it allows efficient storage and retrieval for
sets of text documents, where most words(attribute values) occur only
in few documents. .

d) Thesaurus-based query expansion takes each token, t, from a query,
and adds synonyms for t from a thesaurus.

e) Heaps law is V=Kn^B, where B is approximately 0.5, therefore it says that
the size of the vocabulary (number of distinct words) is proportional to the
square-root of the length of the corpus in words.

f) The server is likely to believe the spider is part of a denial of service
attach and stop processing its requests.

g) K-nearest neighbor is typically better than plain nearest neighbor
because it avoids errors caused by atypical examples and noise in the
labels of examples.

h) Traditional "hard" clustering assigns each instances to exactly one
cluster, while "soft" clustering assigns to each instance a
probability distribution across a set of discovered categories.

i) The "first rater" problem manifests itself when a collaborative
filtering system cannot recommend an item that has not been previously
rated.

j) It can only learn the synaptic weights on a single neuron modelled as a
linear threshold unit and can therefore only learn linearly-separable functions and
cannot learn non-linear functions such as XOR.

k) A metric for comparing the similarity of clusters (i.e. sets) of instances.

l) It linearly combines an estimate of the conditional probability of a word
with an estimate of its prior probability to obtained a final
smoothed conditional probability estimate. 
P(w | c) = lambda * P'(w | c) + (1 - lambda) * P'(w)

m) Compositional semantics computes the meaning of a sentence by recursively
computing a formal meaning representation for each phrase by somehow composing 
(e.g. by function composition) the meanings of its sub-phrases, where
individual word meanings constitute the base case of the recursion.

n) It provides a medium for transparency in which annotators can clearly provide why they make a certain annotation. It improves reliability as people are less likely to randomly make annotations if they must justify it. It allows for easy verifiability as others can go through the annotations later and verify the annotation with guidance provided by the rationale. Finally, due to these improvements in transparency and accountability, it is possible to open up the task to anyone who wants to participate.

o) It prevents all of the page rank from "flowing" into 
sinks in the web graph by constantly "dripping" a fixed
rank into each individual page.  In the random surfer model,
it represents the fixed probability of jumping to a random page.

--

p) Because they are both performing hill-climbing (gradient descent), where at
each iteration they increase the objective function, but this type of local
search does not guarantee that they will reach a global optimum.

q) To prevent floating point underflow that can be easily caused by multiplying 
many small probabilities.

r) Group-average HAC is run on a randomly chosen subset of sqrt(n) 
examples, which takes O((sqrt(n)^2) = O(n) time.  The results of
this run of HAC are then used to generate k seeds for K-means. Since 
K-means also takes O(n) time, the total running time is O(n) + O(n) = O(n).

s) (Extra-credit) Tim Berners-Lee, CERN

u) (Extra-credit) W3C (World Wide Web Consortium)

u) (Extra-credit) Cornell

v) (Extra-credit) Linguistics, UT Austin
